{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_extraction(column):\n",
    "    values = column.unique().tolist()\n",
    "    return {value: index for index, value in enumerate(values)}\n",
    "\n",
    "def labeller(column, feature_name):\n",
    "    \"\"\"Used for Label encoding of catogrical features\"\"\"\n",
    "    return column.apply(lambda x: label_extraction(column)[x])\n",
    "\n",
    "\n",
    "def count_missing_values(df):\n",
    "    \"\"\"For showing missing values\"\"\"\n",
    "    missing_value_count = {}\n",
    "    for column in df.columns:\n",
    "        missing_value_count[labels[column]] = df[column].isna().sum()\n",
    "    \n",
    "    missing_values_df = pd.DataFrame({'Feature': list(missing_value_count.keys()), \n",
    "                                      'No of values missing': list(missing_value_count.values())})\n",
    "    \n",
    "    return missing_values_df\n",
    "\n",
    "def assign_values_by_percentiles(data):\n",
    "    \"\"\"\n",
    "    Assigns values to elements in the data based on predefined percentiles and values.\n",
    "\n",
    "    Parameters:\n",
    "        data (array-like): The data for which values need to be assigned.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the assigned values based on the percentiles.\n",
    "    \"\"\"\n",
    "    # Define percentiles and corresponding values\n",
    "    percentiles = [25, 50, 75, 100]\n",
    "    values = [0.25, .5, 0.75, 1]\n",
    "\n",
    "    # Calculate percentile values\n",
    "    percentile_values = [np.percentile(data, p) for p in percentiles]\n",
    "\n",
    "    # Create a list to store the assigned values\n",
    "    assigned_values = []\n",
    "\n",
    "    # Assign values based on percentiles\n",
    "    for value in data:\n",
    "        if value <= percentile_values[0]:\n",
    "            assigned_values.append(values[0])\n",
    "        elif value <= percentile_values[1]:\n",
    "            assigned_values.append(values[1])\n",
    "        elif value <= percentile_values[2]:\n",
    "            assigned_values.append(values[2])\n",
    "        else:\n",
    "            assigned_values.append(values[3])\n",
    "\n",
    "    return assigned_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for data manipulation, visualization, and model building\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import shap  # Used for model interpretation with SHAP values\n",
    "from math import sqrt  # For mathematical operations\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Importing metrics and tools from scikit-learn for model evaluation\n",
    "from sklearn.metrics import r2_score, mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split  # Splitting data into training and testing sets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor  # Ensemble methods\n",
    "from sklearn.tree import DecisionTreeRegressor  # Decision tree regressor\n",
    "from sklearn.svm import SVR  # Support Vector Regressor\n",
    "from sklearn.multioutput import MultiOutputRegressor  # For multi-output regression\n",
    "from xgboost import XGBRegressor  # Extreme Gradient Boosting\n",
    "from catboost import CatBoostRegressor  # Categorical Boosting\n",
    "from lightgbm import LGBMRegressor  # Light Gradient Boosting Machine\n",
    "\n",
    "# Hyperparameter optimization using Hyperopt\n",
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "\n",
    "# Suppressing warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'mt':'Materials type','btu':'Biochar type (Unmodified or modified)','bt':'Biochar type','bet':'BET surface area (m2/g)','p':'Pore volume (cm3/g)','ph':'solution pH (pHsol)','rt':'Reactor temperature','asc':'Initial As concentration (Total) mg/L','ad':'Adsorbent dosage (g/L)', 'e':'Equilibrium/Reaction time (h)','pt':'Pyrolysis temperature','target':'As(V)'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "y_final=df.target\n",
    "df.drop(columns='target',inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ['mt', 'btu', 'bt']:\n",
    "    print(label_extraction(df[n]))\n",
    "    df[n] = labeller(df[n], n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing_df=df.dropna()                                           #Data with no missing values\n",
    "some_missing_df=df.drop(index=no_missing_df.index.to_list())        #Data with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing_df=no_missing_df.sort_index()\n",
    "x_no_missing=no_missing_df[['mt','btu','bt','asc','pt']]\n",
    "y_no_missing=no_missing_df.drop(columns=['mt','btu','bt','asc','pt'])\n",
    "x_no_missing_train, x_no_missing_test, y_no_missing_train, y_no_missing_test = train_test_split(x_no_missing, y_no_missing, test_size=0.2,random_state=260)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of regression models\n",
    "models = [DecisionTreeRegressor(), RandomForestRegressor(),XGBRegressor(), MultiOutputRegressor(estimator = CatBoostRegressor(verbose=0)),MultiOutputRegressor(estimator = AdaBoostRegressor()),MultiOutputRegressor(estimator=GradientBoostingRegressor())]\n",
    "results={}\n",
    "for model in models:\n",
    "    results[model.__class__.__name__]=fit_and_evaluate_model(model, x_no_missing_train, y_no_missing_train, x_no_missing_test, y_no_missing_test)\n",
    "    accuracies = cross_val_score(estimator = model, X = x_no_missing_train, y= y_no_missing_train, cv=5)\n",
    "    print(f\" Mean Accuracy: {accuracies.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting DecisionTreeRegressor Regression to the Training set wihtout hyperparameter tuning\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "model.fit(x_no_missing_train, y_no_missing_train)\n",
    "\n",
    "#Measure the R2 for training and test set\n",
    "model_score = model.score(x_no_missing_train,y_no_missing_train)\n",
    "\n",
    "y_predicted = model.predict(x_no_missing_test)\n",
    "\n",
    "y_predicted_train = model.predict(x_no_missing_train)\n",
    "\n",
    "print(\"The training R2 is: \", model.score(x_no_missing_train, y_no_missing_train))\n",
    "print(\"The test R2 is: \", model.score(x_no_missing_test, y_no_missing_test))\n",
    "print(\"The R2 is: \", r2_score(y_predicted,y_no_missing_test))\n",
    "\n",
    "\n",
    "\n",
    "# The mean squared error & Variance\n",
    "print(\"MSE: %.2f\"% mse(y_no_missing_test, y_predicted))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_no_missing_train, y_predicted_train)))\n",
    "print(\"RMSE of test set: %.2f\"% sqrt(mse(y_no_missing_test, y_predicted)))\n",
    "\n",
    "\n",
    "#k-cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = model, X = x_no_missing_train, y= y_no_missing_train, cv=5)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "\n",
    "\n",
    "#Plotting the joint plot of  actual v/s predicted\n",
    "pp_tr = model.predict(x_no_missing_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning (Decision Tree Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeRegressor()\n",
    "param_grid = {  \n",
    "\t'max_features': ['sqrt', 'log2', None], \n",
    "\t'max_depth': [3, 6, 9,10,11,12], \n",
    "\t'max_leaf_nodes': [3, 6, 9], \n",
    "}\n",
    "tuning = GridSearchCV(estimator=model, \n",
    "                          param_grid = param_grid,\n",
    "                          cv=3,\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='neg_mean_squared_error')   \n",
    "tuning.fit(x_no_missing_train, y_no_missing_train)\n",
    "print(\"Best parameters:\")\n",
    "print(tuning.best_params_)\n",
    "random_forest_tuned_results=fit_and_evaluate_model(DecisionTreeRegressor(), x_no_missing_train, y_no_missing_train, x_no_missing_test, y_no_missing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=some_missing_df[['mt','btu','bt','asc','pt']]\n",
    "results=model.predict(features) #predicting\n",
    "results=pd.DataFrame(results,columns=['bet','p','ph','rt','ad','e'],index=features.index) #forming a DataFrame\n",
    "df_complete=df.combine_first(results) #combinging with original dataset to replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete['target']=y_final\n",
    "print(df_complete[df_complete['target'].isna()])\n",
    "df=df_complete.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explodatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "heatmap=sns.heatmap(df.corr(),annot=True,cmap='YlGnBu')\n",
    "heatmap.set_xticklabels([labels[n] for n in df.columns if n in df.columns],rotation=90)\n",
    "heatmap.set_yticklabels([labels[n] for n in df.columns if n in df.columns],rotation=0)\n",
    "plt.title('Pearson Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "num_cols = df.shape[1]\n",
    "num_rows = (num_cols - 1) // 3 + 1\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 5))\n",
    "\n",
    "if num_rows == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each column and plot histogram\n",
    "for i, col in enumerate(df.columns):\n",
    "    ax = axes[i // 3][i % 3]\n",
    "    sns.histplot(df[col], ax=ax, kde=True, color='skyblue', bins=20)\n",
    "    ax.set_title(labels[col], fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.grid(False)\n",
    "\n",
    "# Remove empty subplot(s) if any\n",
    "for i in range(num_cols, num_rows * 3):\n",
    "    fig.delaxes(axes[i // 3][i % 3])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split\n",
    "70% for Training\n",
    "15% for validation\n",
    "15% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "x = df.drop(columns='target')\n",
    "y = df['target']\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models Without tuning.\n",
    "1. XGBregressor\n",
    "2. Catboost\n",
    "3. LGMregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "plt.rcdefaults()\n",
    "model = XGBRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model_score = model.score(x_train,y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "y_predicted_train = model.predict(x_train)\n",
    "print(\"The training R2 is: \", model.score(x_train, y_train))\n",
    "print(\"The test R2 is: \", model.score(x_test, y_test))\n",
    "print(\"The model R2 is: \", r2_score(y_test, y_predicted))\n",
    "print(\"MSE: %.2f\"% mse(y_test, y_predicted))\n",
    "print(\"RMSE of model: %.2f\"% sqrt(mse(y_test, y_predicted)))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_train, y_predicted_train)))\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv=3)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "pp_tr = model.predict(x_train)\n",
    "g = sns.JointGrid(x=y_test, y=y_predicted)\n",
    "sns.scatterplot(x=y_train, y=pp_tr, s=100, color='orange', ax=g.ax_joint)\n",
    "sns.scatterplot(x=y_test, y=y_predicted, s=100, color='blue', ax=g.ax_joint)\n",
    "sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint)\n",
    "g.set_axis_labels(\"Actual\", \"Predicted\", fontsize =22, fontname = 'Times New Roman')\n",
    "sns.histplot(x=y_train,ax=g.ax_marg_x, color ='orange')\n",
    "sns.histplot(x=y_test, ax=g.ax_marg_x, color ='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(verbose=0)\n",
    "model.fit(x_train, y_train)\n",
    "model_score = model.score(x_train,y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "y_predicted_train = model.predict(x_train)\n",
    "print(\"The training R2 is: \", model.score(x_train, y_train))\n",
    "print(\"The test R2 is: \", model.score(x_test, y_test))\n",
    "print(\"The model R2 is: \", r2_score(y_test, y_predicted))\n",
    "print(\"MSE: %.2f\"% mse(y_test, y_predicted))\n",
    "print(\"RMSE of model: %.2f\"% sqrt(mse(y_test, y_predicted)))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_train, y_predicted_train)))\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv=10)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "pp_tr = model.predict(x_train)\n",
    "g = sns.JointGrid(x=y_test, y=y_predicted)\n",
    "sns.scatterplot(x=y_train, y=pp_tr, s=100, color='orange', ax=g.ax_joint)\n",
    "sns.scatterplot(x=y_test, y=y_predicted, s=100, color='blue', ax=g.ax_joint)\n",
    "sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint)\n",
    "g.set_axis_labels(\"Actual\", \"Predicted\", fontsize =22, fontname = 'Times New Roman')\n",
    "sns.histplot(x=y_train,ax=g.ax_marg_x, color ='orange')\n",
    "sns.histplot(x=y_test, ax=g.ax_marg_x, color ='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(verbose=-1)\n",
    "model.fit(x_train, y_train)\n",
    "model_score = model.score(x_train,y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "y_predicted_train = model.predict(x_train)\n",
    "print(\"The training R2 is: \", model.score(x_train, y_train))\n",
    "print(\"The test R2 is: \", model.score(x_test, y_test))\n",
    "print(\"The model R2 is: \", r2_score(y_test, y_predicted))\n",
    "print(\"MSE: %.2f\"% mse(y_test, y_predicted))\n",
    "print(\"RMSE of model: %.2f\"% sqrt(mse(y_test, y_predicted)))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_train, y_predicted_train)))\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv=3)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "pp_tr = model.predict(x_train)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "g = sns.JointGrid(x=y_test, y=y_predicted)\n",
    "sns.scatterplot(x=y_train, y=pp_tr, s=100, color='orange', ax=g.ax_joint)\n",
    "sns.scatterplot(x=y_test, y=y_predicted, s=100, color='blue', ax=g.ax_joint)\n",
    "sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint)\n",
    "g.set_axis_labels(\"Actual\", \"Predicted\", fontsize =22, fontname = 'Times New Roman')\n",
    "sns.histplot(x=y_train,ax=g.ax_marg_x, color ='orange')\n",
    "sns.histplot(x=y_test, ax=g.ax_marg_x, color ='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "1. XGBregressor (Cross-Valnidation)\n",
    "2. Catboost (Bayesian)\n",
    "3. LGBregressor (Cross-Valnidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "param_grid = {'eta':[0.05,0.1,0.15,0.2],\n",
    "                 'max_depth':[4,6,8,10],\n",
    "                 'subsample':[0.5,1],\n",
    "                 'colsample_bytree':[0.5,1],\n",
    "                 'eval_metric':['rmse'],\n",
    "                 'seed':[42],\n",
    "                 'n_estimators':np.arange(100,1001,100).tolist()}\n",
    "\n",
    "tuning = GridSearchCV(estimator=model, \n",
    "                          param_grid = param_grid,\n",
    "                          cv=3,\n",
    "                          verbose=1,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='neg_mean_squared_error')\n",
    "tuning.fit(x_train, y_train)\n",
    "print(\"Best parameters:\")\n",
    "print(tuning.best_params_)\n",
    "\n",
    "model = XGBRegressor(**tuning.best_params_)\n",
    "model.fit(x_train, y_train)\n",
    "model_score = model.score(x_train,y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "y_predicted_train = model.predict(x_train)\n",
    "print(\"The training R2 is: \", model.score(x_train, y_train))\n",
    "print(\"The test R2 is: \", model.score(x_test, y_test))\n",
    "print(\"The model R2 is: \", r2_score(y_test, y_predicted))\n",
    "print(\"MSE: %.2f\"% mse(y_test, y_predicted))\n",
    "print(\"RMSE of model: %.2f\"% sqrt(mse(y_test, y_predicted)))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_train, y_predicted_train)))\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv=3)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "pp_tr = model.predict(x_train)\n",
    "g = sns.JointGrid(x=y_test, y=y_predicted)\n",
    "sns.scatterplot(x=y_train, y=pp_tr, s=100, color='orange', ax=g.ax_joint)\n",
    "sns.scatterplot(x=y_test, y=y_predicted, s=100, color='blue', ax=g.ax_joint)\n",
    "sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint)\n",
    "g.set_axis_labels(\"Actual\", \"Predicted\", fontsize =22, fontname = 'Times New Roman')\n",
    "sns.histplot(x=y_train,ax=g.ax_marg_x, color ='orange')\n",
    "sns.histplot(x=y_test, ax=g.ax_marg_x, color ='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'depth': hp.quniform('depth', 4, 12, 1),\n",
    "    'l2_leaf_reg': hp.loguniform('l2_leaf_reg', np.log(1), np.log(100)),\n",
    "    'iterations': hp.quniform('iterations', 100, 1000, 50),\n",
    "    'max_bin': hp.quniform('max_bin', 4, 255, 1),\n",
    "}\n",
    "def objective(params):\n",
    "    model = CatBoostRegressor(**params, verbose=0)\n",
    "    model.fit(x_train, y_train)\n",
    "    score = mse(model.predict(x_test), y_test)**0.5\n",
    "    return score\n",
    "trials = Trials()\n",
    "best_params = fmin(fn=objective,\n",
    "                   space=space,\n",
    "                   algo=tpe.suggest,\n",
    "                   max_evals=50,\n",
    "                   trials=trials)\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "cat_boost_tuned_results=fit_and_evaluate_model(CatBoostRegressor(**best_params,verbose=False),  x_train, y_train, x_test, y_test)\n",
    "model = CatBoostRegressor(**best_params,verbose=False)\n",
    "model.fit(x_train, y_train)\n",
    "model_score = model.score(x_train,y_train)\n",
    "y_predicted = model.predict(x_test)\n",
    "y_predicted_train = model.predict(x_train)\n",
    "print(\"The training R2 is: \", model.score(x_train, y_train))\n",
    "print(\"The test R2 is: \", model.score(x_test, y_test))\n",
    "print(\"The model R2 is: \", r2_score(y_test, y_predicted))\n",
    "print(\"MSE: %.2f\"% mse(y_test, y_predicted))\n",
    "print(\"RMSE of model: %.2f\"% sqrt(mse(y_test, y_predicted)))\n",
    "print(\"RMSE of train set: %.2f\"% sqrt(mse(y_train, y_predicted_train)))\n",
    "accuracies = cross_val_score(estimator = model, X = x_train, y= y_train, cv=3)\n",
    "print(\"The mean accuracy is: \", accuracies.mean())\n",
    "pp_tr = model.predict(x_train)\n",
    "g = sns.JointGrid(x=y_test, y=y_predicted)\n",
    "sns.scatterplot(x=y_train, y=pp_tr, s=100, color='orange', ax=g.ax_joint)\n",
    "sns.scatterplot(x=y_test, y=y_predicted, s=100, color='blue', ax=g.ax_joint)\n",
    "sns.regplot(x=y_test, y=y_predicted, ax=g.ax_joint)\n",
    "g.set_axis_labels(\"Actual\", \"Predicted\", fontsize =22, fontname = 'Times New Roman')\n",
    "sns.histplot(x=y_train,ax=g.ax_marg_x, color ='orange')\n",
    "sns.histplot(x=y_test, ax=g.ax_marg_x, color ='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer1 = shap.Explainer(model)\n",
    "shap_values1 = explainer1(x_train)\n",
    "shap.plots.bar(shap_values1, max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values1, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping model for Web modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('model.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization (Genetic Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geneticalgorithm import geneticalgorithm as ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized implementation of a genetic algorithm using the geneticalgorithm package from the repository\n",
    "https://github.com/rmsolgi/geneticalgorithm/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to folder (optimization) for complete information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective function (refer to publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "\n",
    "    prediction=model.predict(params)\n",
    "    prediction=(prediction-df.target.min())/(df.target.max()-df.target.min())\n",
    "\n",
    "    #scaling\n",
    "    rt=(params[-5]-df.rt.min())/(df.rt.max()-df.rt.min())   \n",
    "    e=(params[-2]-df.e.min())/(df.e.max()-df.e.min())\n",
    "    \n",
    "    #score\n",
    "    score = -prediction +  rt + e\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gas(varbound):\n",
    "    \"\"\"\n",
    "    Run genetic algorithm optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    varbound (ndarray): Array of variable boundaries for optimization.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: The final score, model prediction, and genetic algorithm report.\n",
    "    \"\"\"\n",
    "    ga_model = ga(\n",
    "        function=objective,\n",
    "        dimension=11,\n",
    "        variable_type_mixed=np.array(['int', 'int', 'int', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'int']),\n",
    "        variable_boundaries=varbound,\n",
    "        algorithm_parameters={\n",
    "            'max_num_iteration': 500,\n",
    "            'population_size': 200,\n",
    "            'mutation_probability': 0.1,\n",
    "            'elit_ratio': 0.01,\n",
    "            'crossover_probability': 0.5,\n",
    "            'parents_portion': 0.3,\n",
    "            'crossover_type': 'uniform',\n",
    "            'max_iteration_without_improv': None\n",
    "        }\n",
    "    )\n",
    "    ga_model.run()\n",
    "    final_params = ga_model.output_dict['variable']\n",
    "    final_score = -model_cat.predict(final_params) + final_params[-5] + final_params[-2]\n",
    "    print(f\"Final Score: {final_score}, Model Prediction: {model_cat.predict(final_params)}\")\n",
    "    return ga_model.output_dict['variable'],final_score, model_cat.predict(final_params), ga_model.report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization function\n",
    "def run_optimization(t):\n",
    "    \"\"\"\n",
    "    Run optimization for a given t value.\n",
    "    Runs the sovler 10 times to reduce randomness\n",
    "    Parameters:\n",
    "    t (float): Fixed value for 'Initial Asc. Conc' parameter.\n",
    "    \"\"\"\n",
    "    varbound = np.array([\n",
    "        [df.mt.min(), df.mt.max()],\n",
    "        [df.btu.min(), df.btu.max()],\n",
    "        [df.bt.min(), df.bt.max()],\n",
    "        [df.bet.min(), df.bet.max()],\n",
    "        [df.p.min(), df.p.max()],\n",
    "        [df.ph.min(), df.ph.max()],\n",
    "        [df.rt.min(), df.rt.max()],\n",
    "        [t, t],  # 'asc' parameter fixed\n",
    "        [df.ad.min(), df.ad.max()],\n",
    "        [df.e.min(), df.e.max()],\n",
    "        [df.pt.min(), df.pt.max()]\n",
    "    ])\n",
    "    \n",
    "    results = {}\n",
    "    for n in range(10):\n",
    "        print(f\"t={t}, iteration={n}\", end=',')\n",
    "        results[n] = gas(varbound)\n",
    "        \n",
    "    results_df = pd.DataFrame(results, index=['input_parameters','objective_function', 'model_prediction', 'result'])\n",
    "    results_df.to_csv(f\"optimizing_results_{t}.csv\")\n",
    "\n",
    "# Example usage: run optimization for the first t value\n",
    "t_values = [0.6710000000000002, 2.2860000000000005, 4.993, 9.97, 10.8, 20.0, 40.0, 74.97000000000001, 100.0, 1001.07] # 10-100percentile values of Int. asc conc.\n",
    "run_optimization(t_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REFER TO OPTIMIZATION.ZIP for each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'mt': 'M. type',\n",
    "    'btu': 'BioC. type(Unmodified or modified)',\n",
    "    'bt': 'B. type',\n",
    "    'bet': 'BET S. area (m²/g)',\n",
    "    'p': 'P. vol (cm³/g)',\n",
    "    'ph': 'Sol. pH (pHsol)',\n",
    "    'rt': 'Rx. temp (°C)',\n",
    "    'asc': 'Int. As conc. Total (mg/L)',\n",
    "    'ad': 'Ad. dosage (g/L)',\n",
    "    'e': 'Rx. time (h)',\n",
    "    'pt': 'P. temp (°C)',\n",
    "    'target': 'As(V) (mg/g)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {\n",
    "    0: 'Clay and Silica-based Materials',              # bentonite\n",
    "    1: 'Clay and Silica-based Materials',              # clay\n",
    "    2: 'Aluminum and Iron-based Compounds',            # Boehmite\n",
    "    3: 'Aluminum and Iron-based Compounds',            # FeOx\n",
    "    4: 'Aluminum and Iron-based Compounds',            # alumipowder\n",
    "    5: 'Aluminum and Iron-based Compounds',            # maghemite\n",
    "    6: 'Aluminum and Iron-based Compounds',            # Hematite\n",
    "    7: 'Aluminum and Iron-based Compounds',            # magnetite\n",
    "    8: 'Aluminum and Iron-based Compounds',            # ironManganeseOxides\n",
    "    9: 'Metal-Organic Frameworks (MOFs)',              # MOF\n",
    "    10: 'Carbon-based Materials',                      # Orderedmesoporouscarbon\n",
    "    11: 'Carbon-based Materials',                      # grapheneoxide-carbonnotubesaerogel\n",
    "    12: 'Carbon-based Materials',                      # activatedcarbon\n",
    "    13: 'Organic and Biopolymer Materials',            # calciumalgitebeads\n",
    "    14: 'Carbon-based Materials',                      # activatedcarbonfiber\n",
    "    15: 'Carbon-based Materials',                      # graphene\n",
    "    16: 'Carbon-based Materials',                      # ricestrawbiochar\n",
    "    17: 'Aluminum and Iron-based Compounds',           # goethite\n",
    "    18: 'Carbon-based Materials',                      # biochar\n",
    "    19: 'Aluminum and Iron-based Compounds',           # Iron-BasedSorbent\n",
    "    20: 'Aluminum and Iron-based Compounds',           # Fe-Al\n",
    "    21: 'Aluminum and Iron-based Compounds',           # Fe\n",
    "    22: 'Aluminum and Iron-based Compounds',           # Ferric-basedlayereddoublehydroxide\n",
    "    23: 'Clay and Silica-based Materials',             # MCM-41\n",
    "    24: 'Clay and Silica-based Materials',             # poroussilica\n",
    "    25: 'Organic and Biopolymer Materials',            # fibers(V)\n",
    "    26: 'Organic and Biopolymer Materials',            # TEMPO(2,2,6,6-tetramethylpiperidine-1-oxyl)\n",
    "    27: 'Organic and Biopolymer Materials',            # polyvinylalcohol\n",
    "    28: 'Waste-derived Materials',                     # Eggshell\n",
    "    29: 'Waste-derived Materials',                     # Wastecementpowder\n",
    "    30: 'Waste-derived Materials',                     # Concretesludge\n",
    "    31: 'Organic and Biopolymer Materials'             # magneticchitosannoparticle\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terenary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "# Assuming df is your DataFrame containing data\n",
    "# Assigning color and symbol based on the legend mapping\n",
    "color_and_symbol = [legend[code] for code in df.mt]\n",
    "\n",
    "fig = px.scatter_ternary(df, \n",
    "                         a='bet', \n",
    "                         b='asc', \n",
    "                         c='rt', \n",
    "                         color=df.target, \n",
    "                         size=assign_values_by_percentiles(df.pt), \n",
    "                         symbol=color_and_symbol,\n",
    "                         symbol_sequence=['circle','triangle-up','cross','star'],\n",
    "                         width=1600, \n",
    "                         height=1200, \n",
    "                         opacity=0.7, \n",
    "                         color_continuous_scale='bluered')\n",
    "\n",
    "fig.update_layout(\n",
    "    font=dict(family=\"Arial\", color=\"black\", size=24),\n",
    "    ternary=dict(\n",
    "        sum=1,\n",
    "        bgcolor='white',\n",
    "        aaxis=dict(\n",
    "            min=0,\n",
    "            linewidth=2,\n",
    "            ticks='outside',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "            ticktext=['0', '', '10', '', '20', '', '30', '', '40', '', '50', '', '60', '', '70', '', '80', '', '90', '', '100'],\n",
    "            linecolor='black',\n",
    "            title=''\n",
    "        ),\n",
    "        baxis=dict(\n",
    "            min=0,\n",
    "            linewidth=2,\n",
    "            ticks='outside',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "            ticktext=['0', '', '10', '', '20', '', '30', '', '40', '', '50', '', '60', '', '70', '', '80', '', '90', '', '100'],\n",
    "            linecolor='black',\n",
    "            title='',\n",
    "        ),\n",
    "        caxis=dict(\n",
    "            min=0,\n",
    "            linewidth=2,\n",
    "            ticks='outside',\n",
    "            tickmode='array',\n",
    "            tickvals=[0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "            ticktext=['0', '', '10', '', '20', '', '30', '', '40', '', '50', '', '60', '', '70', '', '80', '', '90', '', '100'],\n",
    "            linecolor='black',\n",
    "            title='' \n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Change the color of grid lines\n",
    "fig.update_layout(ternary=dict(\n",
    "    aaxis=dict(gridcolor='grey'),  \n",
    "    baxis=dict(gridcolor='grey'),  \n",
    "    caxis=dict(gridcolor='grey')   \n",
    "))\n",
    "\n",
    "# Adjusting legend position\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=1,\n",
    "    xanchor=\"right\",\n",
    "    x=0.99,title=\"M. type\",\n",
    "    font=dict(size=24)\n",
    "))\n",
    "fig.update_layout(coloraxis_colorbar=dict(\n",
    "    title=\"As(V)(mg/g)\",\n",
    "    showticklabels=False\n",
    "))\n",
    "fig.update_coloraxes(showscale=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Violot plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df.copy()\n",
    "temp_df['btu']=temp_df['btu'].apply(lambda x: 'Unmodified' if x == 0 else 'Modified')\n",
    "\n",
    "# Set the style using plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-poster')\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(data=temp_df, y='target', hue='btu', split=True, inner=None,\n",
    "               palette={'Unmodified': 'red', 'Modified': '#FF6600'}, alpha=.6, ax=ax,linecolor='black')\n",
    "\n",
    "# Labels and legend\n",
    "ax.set_ylabel('As(V) (mg/g)', fontdict={\"family\": 'Arial', 'color': 'black', 'size': 28})\n",
    "ax.set_xlabel('BioC. type', fontdict={\"family\": 'Arial', 'color': 'black', 'size': 28})\n",
    "ax.legend(title=\"BioC. type\", title_fontsize=28, fontsize=24)\n",
    "ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "ax.set_ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Heatmap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = df.drop(columns=['mt','btu','bt'])  # removing catogorical plot\n",
    "t_df.columns = [labels[n] for n in t_df.columns]\n",
    "\n",
    "correlation_matrix = t_df.corr()\n",
    "\n",
    "# Create an upper triangular matrix of ones with the same shape as the correlation matrix\n",
    "upper_triangular_ones = np.triu(np.ones_like(correlation_matrix))\n",
    "\n",
    "# Replace diagonal elements with zeros\n",
    "np.fill_diagonal(upper_triangular_ones, 0)\n",
    "\n",
    "plt.figure(figsize=(8,6),dpi=300)\n",
    "sns.heatmap(t_df.corr(), cmap=sns.color_palette('YlGnBu',as_cmap=True), annot=False, mask=upper_triangular_ones)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar Plots\n",
    "\n",
    "update \"asd\" variable for barplot for diffirent features\n",
    "update \"colors\" for changing color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = ['p']\n",
    "colors= \"#8bd3c7\"\n",
    "variable = [labels[n] for n in asd]\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "\n",
    "# Boxplot\n",
    "boxprops = dict(facecolor=colors, edgecolor='black', linewidth=2)\n",
    "whiskerprops = dict(color='black', linewidth=2)\n",
    "capprops = dict(color='black', linewidth=2)\n",
    "medianprops = dict(color='black', linewidth=2)\n",
    "flierprops = dict(marker='o', color='black', markersize=0.00001)\n",
    "\n",
    "# Plotting boxplot\n",
    "positions = range(len(asd))\n",
    "boxplot = plt.boxplot(\n",
    "    x=[t_df[label] for label in variable],\n",
    "    patch_artist=True,\n",
    "    positions=positions,\n",
    "    widths=0.4,  # Width of the box\n",
    "    boxprops=boxprops,\n",
    "    whiskerprops=whiskerprops,\n",
    "    capprops=capprops,\n",
    "    medianprops=medianprops,\n",
    "    flierprops=flierprops\n",
    ")\n",
    "\n",
    "# Scatter plot for maximum values\n",
    "for i, label in enumerate(variable):\n",
    "    max_value = t_df[label].max()\n",
    "    plt.scatter(positions[i], max_value, marker='v', color='black', s=100, zorder=3, label=f'Max {label}')\n",
    "\n",
    "# Create legend\n",
    "box_legend = plt.Rectangle((0, 0), 1, 1, fc=colors, edgecolor='black', linewidth=2, label='25%~75%')\n",
    "scatter_legend = plt.Line2D([], [], marker='v', color='black', linestyle='None', markersize=10, label='Max Value')\n",
    "\n",
    "# Plotting 25th and 75th percentiles as horizontal lines\n",
    "median_legend = plt.Line2D([], [], color='black', linewidth=2, label='Median')\n",
    "\n",
    "#plt.legend(handles=[box_legend, scatter_legend, median_legend], loc='upper left', fontsize=24,prop={'family': 'Arial'})      ##(Remove the starting # to add legend)\n",
    "plt.xticks(positions, variable, fontsize=24, fontname='Arial')\n",
    "plt.yticks(fontsize=24, fontname='Arial')  # Adjust y-ticks\n",
    "\n",
    "plt.savefig('_'.join(asd) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shap Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The data\n",
    "data = {\n",
    "    \"asc\": 19.44,\n",
    "    \"ad\": 14.49,\n",
    "    'pt':8.05,\n",
    "    'e':7.1,\n",
    "    \"mt\": 4.93,\n",
    "    \"bt\": 4.37,\n",
    "    \"bet\": 4.1,\n",
    "    \"p\": 4.05,\n",
    "    \"ph\": 2.95,\n",
    "    \"btu\": 2.4,\n",
    "    \"rt\": 1.1\n",
    "}\n",
    "\n",
    "total = sum(data.values())\n",
    "# Convert values to percentages\n",
    "percentages = {k: (v / total) * 100 for k, v in data.items()}\n",
    "sorted_percentages = dict(sorted(percentages.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "bars = ax.barh(list(percentages.keys()), list(percentages.values()), color='#126994',alpha=1, edgecolor='black',linewidth=1)\n",
    "\n",
    "# Add labels and title with specified font style and size\n",
    "ax.set_xlabel('Percentage Contribution(%)', fontname='Arial', fontsize=28)\n",
    "\n",
    "# Annotate each bar with its percentage value\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 0.6, bar.get_y() + bar.get_height()/2, f'{width:.1f}%', va='center', fontname='Arial', fontsize=20,color='#126994')\n",
    "ax.set_yticklabels([labels[key] for key in list(percentages.keys())], fontname='Arial', fontsize=24)\n",
    "ax.set_xlim(0, 33)\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence Interval Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=[193.237276\n",
    ",\n",
    "      198.8241923\n",
    ",\n",
    "      175.7726192\n",
    ",\n",
    "      207.2319105\n",
    ",\n",
    "      206.0417048\n",
    ",\n",
    "      217.7694266\n",
    ",\n",
    "      205.2294573\n",
    ",\n",
    "      253.2950474\n",
    ",\n",
    "      271.5617158\n",
    ",\n",
    "      247.4990662\n",
    ",\n",
    "      265.5606908\n",
    "\n",
    "      ]\n",
    "\n",
    "data=pd.read_csv('utils\\\\as5.csv',header=None)\n",
    "\n",
    "lower=[]\n",
    "upper=[]\n",
    "for n in range(len(data.columns)):\n",
    "    mean=data[n].mean()\n",
    "    std=data[n].std()\n",
    "    lower.append(data[n].max() - 2.262 * std) #2.626 calculted from z-distriution function\n",
    "    upper.append(data[n].max() + 2.262 * std)\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "for i in range(len(best)):\n",
    "    plt.plot(best[:i+1], color='red', linewidth=2)\n",
    "    plt.fill_between(range(i+1), lower[:i+1], upper[:i+1], color='#ffe4e1', alpha=0.5)\n",
    "    plt.ylabel(labels['target'], fontdict={\"family\": 'Arial', 'size': 24})\n",
    "    plt.xlabel(labels['asc'], fontdict={\"family\": 'Arial', 'size': 24})\n",
    "    \n",
    "    # Set x-tick labels with custom formatting\n",
    "    x_ticks_labels = [f'{n*10} percentile' for n in range(1, 11)]\n",
    "    x_ticks_labels.append('Complete Range')\n",
    "    plt.xticks(range(len(x_ticks_labels)), x_ticks_labels, fontsize=20, fontname='Arial', rotation=90)\n",
    "    plt.yticks(fontsize=20, fontname='Arial')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Interval plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=pd.read_csv('utils\\\\x_valid.csv')\n",
    "y_valid=pd.read_csv('utils\\\\y_valid.csv')\n",
    "x_test=pd.read_csv('utils\\\\x_test.csv')\n",
    "y_test=pd.read_csv('utils\\\\y_test.csv')\n",
    "y_pred=model.predict(x_valid)\n",
    "y_pred_cat=pd.read_csv('utils\\\\cat_boost_tuned_results.csv',header=None)\n",
    "\n",
    "upper=y_pred_cat+np.percentile(y_pred-y_valid.target, 95)\n",
    "lower=y_pred_cat-np.percentile(y_pred-y_valid.target, 95)\n",
    "\n",
    "\n",
    "# Sorting y_test and corresponding upper, lower, y_pred_test_2\n",
    "y_test_sorted = y_test.sort_values(by='target').reset_index(drop=True)\n",
    "upper_sorted = pd.Series(upper[0]).sort_values().reset_index(drop=True)\n",
    "lower_sorted = pd.Series(lower[0]).sort_values().reset_index(drop=True)\n",
    "y_pred_test_sorted = pd.Series(y_pred_cat[0]).sort_values().reset_index(drop=True)\n",
    "\n",
    "# Create the figure and axis\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Remove the top and right spines\n",
    "\n",
    "# Plotting the actual values\n",
    "sns.lineplot(x=y_test_sorted.index, y=y_test_sorted['target'], ax=ax, label='True', color='red', alpha=1)\n",
    "\n",
    "# Fill between the upper and lower confidence bounds\n",
    "plt.fill_between(y_test_sorted.index, upper_sorted, lower_sorted, alpha=0.3, color='grey', label='Prediction Interval')\n",
    "\n",
    "# Set labels\n",
    "ax.set_ylabel('As(III) (mg/g)', fontdict={\"family\": 'Arial', 'color': 'black', 'size': 24})\n",
    "ax.set_xlabel('Test Samples', fontdict={\"family\": 'Arial', 'color': 'black', 'size': 24})\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "# Set legend\n",
    "ax.legend(title=\"\", title_fontsize=20, fontsize=16, loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
